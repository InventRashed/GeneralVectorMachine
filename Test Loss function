
import pandas as pd
import numpy as np
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense
import keras.backend as K
import keras as keras
import sklearn as sk
import sklearn.model_selection
from numpy.random import seed
from keras import utils as np_utils


#Load data
location = "....\breast-cancer-wisconsin.csv"
df_BC = pd.read_csv(location, header=None)
#input column names
df_BC.columns = ['ID', 'Clump thickness', 'Uniformity of Cell Size','Uniformity of Cell Shape',
                 'Marginal Adhesion', 'Single Epithelial Cell Size',
                 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 
                 'Mitoses', 'Class']
#change index to ID
df_BC.index = df_BC['ID']
df_BC.drop(['ID'], axis=1, inplace=True)
df_BC = df_BC[df_BC['Bare Nuclei']!='?']
#split X and y
X = df_BC.iloc[:,0:9]
X_t = np.asarray(X).astype(np.int)
#preprocess X
scaler = sk.preprocessing.MinMaxScaler()
Xscaled = scaler.fit_transform(X_t)
#change y to a 2D array
y = df_BC.iloc[:,-1]
y = np.where(y==4, -1, y) #malignent, bad, minority class
y = np.where(y==2, 1, y) #benign, good, majority class
zeros = np.zeros(len(y))
y_new = np.c_[y, zeros]
for i in range(len(y)):
    if y_new[i,0]==1:
        y_new[i,1] = -1
    else:
        y_new[i,1]= 1

    
#split in training and test data
X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(
    Xscaled, y_new, test_size=0.333)
#initialize model
#need custom activation and loss function also custom initializer
#need to initialize the network with hidden weights and bias between -1 and +1
#Output weight is set to -1 or +1, transfer function coefficient to 1
#Set number of nodes in hidden layer

def initializeOutputWeights(shape, dtype=None):
    #initialize the weights of the output node
    randoms = np.random.randint(low=2, size=shape)
    new = np.where(randoms==0, -1, randoms)
    return K.variable(new, dtype=dtype)

class customLoss(keras.losses.Loss):
    def __init__(self, d=10, name = "CustomLoss"):
        super().__init__(name=name)
        self.d = d    
        
    def call(self,y_true, y_pred):
        N = len(y_true)
        L = len(y_pred[0])
        y_dot = y_pred*y_true
        y_d = y_dot-self.d
        y_square= y_d*y_d
        index_replace = y_dot>self.d
        idx_replace=tf.where(index_replace==True)
        y_loss = tf.tensor_scatter_nd_update(y_square, idx_replace, tf.zeros(len(idx_replace)))
        return tf.divide(K.sum(K.sum(y_loss, axis=1)),tf.cast(N*L, tf.float32))


seed(1)
tf.random.set_seed(2)

model2 = Sequential()
initializer = tf.keras.initializers.RandomUniform(minval=-1, maxval=1)
b = np.ones(20)
model2.add(Dense(20, input_dim=9, name='hidden', kernel_initializer=initializer, 
                 bias_initializer=initializer, activation = lambda x: K.tanh(b*x)))#activation='tanh'))
model2.add(Dense(2, activation='linear', name='output', use_bias=False, trainable=False,kernel_initializer= lambda shape, 
                 dtype: initializeOutputWeights(shape, dtype)))
startingWeights = model2.get_weights()
model2.compile(loss=customLoss(d=16), optimizer='adam', metrics=(['accuracy']))
model2.fit(X_train,y_train, epochs=150, batch_size=10, validation_data=(X_test, y_test))

accuracy = model2.evaluate(X_test,y_test, verbose=1)
y_predict = model2.predict(X_test)
lossvalue = customLoss(d=16).call(y_test, y_predict)
#print('Accuracy: %.2f' %(accuracy*100))

outputWeights2 = model2.get_weights()
outputs2 = [K.function([model2.input], [layer.output])(Xscaled) for layer in model2.layers]
print(outputs2)
